{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d02fd30",
   "metadata": {},
   "source": [
    "# ðŸ• Phase-3.1: Adaptive Time Window Manager\n",
    "## Temporal Reasoning for RAG-IDS\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ¯ **Objective**\n",
    "\n",
    "Implement an adaptive temporal window manager for network flows that:\n",
    "- Maintains a rolling buffer of recent flows\n",
    "- Dynamically expands window when similarity density increases\n",
    "- Dynamically shrinks window when patterns dissipate\n",
    "- Provides O(1) amortized performance\n",
    "\n",
    "### ðŸ“Š **Key Principles**\n",
    "\n",
    "1. **Single flow â‰  Attack**: Decisions emerge from repeated behavior over time\n",
    "2. **Adaptive sizing**: Window expands during attack sequences, shrinks during benign periods\n",
    "3. **Efficiency**: O(1) amortized updates using deque data structure\n",
    "4. **Explainability**: Track window state (expanding/stable/contracting)\n",
    "\n",
    "### ðŸ”§ **Window Behavior**\n",
    "\n",
    "**Expansion Triggers:**\n",
    "- High average similarity (>0.75)\n",
    "- Repeated attack type appearances\n",
    "\n",
    "**Shrinkage Triggers:**\n",
    "- Low average similarity (<0.50)\n",
    "- Stable benign patterns\n",
    "\n",
    "**Constraints:**\n",
    "- Min: 5 seconds / 20 flows\n",
    "- Max: 60 seconds / 500 flows\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3390413a",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "631bbd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Any, Optional\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "print(\"âœ… Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e130904",
   "metadata": {},
   "source": [
    "## ðŸ—ï¸ Data Structures\n",
    "\n",
    "### FlowRecord\n",
    "Represents a single network flow with temporal and retrieval context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fce097f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FlowRecord dataclass defined\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class FlowRecord:\n",
    "    \"\"\"\n",
    "    Represents a single network flow with its temporal and retrieval context.\n",
    "    \n",
    "    Attributes:\n",
    "        flow_id: Unique identifier for the flow\n",
    "        timestamp: Unix timestamp (seconds)\n",
    "        vector_embedding: 99-dimensional feature vector\n",
    "        retrieval_results: ChromaDB k-NN matches with similarity scores\n",
    "        metadata: Additional flow metadata (proto, port, etc.)\n",
    "    \"\"\"\n",
    "    flow_id: str\n",
    "    timestamp: float\n",
    "    vector_embedding: np.ndarray\n",
    "    retrieval_results: Optional[List[Dict[str, Any]]] = None  # ChromaDB matches (can be None if not retrieved yet)\n",
    "    metadata: Dict[str, Any] = field(default_factory=dict)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Validate flow record after initialization.\"\"\"\n",
    "        if len(self.vector_embedding) != 99:\n",
    "            raise ValueError(f\"Expected 99-dimensional vector, got {len(self.vector_embedding)}\")\n",
    "\n",
    "print(\"âœ… FlowRecord dataclass defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5e9ddb",
   "metadata": {},
   "source": [
    "## ðŸªŸ AdaptiveTimeWindow Class\n",
    "\n",
    "Core temporal window manager with adaptive sizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a010632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… AdaptiveTimeWindow class defined\n"
     ]
    }
   ],
   "source": [
    "class AdaptiveTimeWindow:\n",
    "    \"\"\"\n",
    "    Adaptive temporal window manager for behavioral pattern detection.\n",
    "    \n",
    "    The window dynamically adjusts its size based on:\n",
    "    1. Similarity density: More high-similarity matches â†’ expand window\n",
    "    2. Pattern recurrence: Repeated attack types â†’ expand window\n",
    "    3. Pattern dissipation: Low similarity or no patterns â†’ shrink window\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        min_time_seconds: float = 5.0,\n",
    "        max_time_seconds: float = 60.0,\n",
    "        min_flow_count: int = 20,\n",
    "        max_flow_count: int = 500,\n",
    "        similarity_expansion_threshold: float = 0.75,\n",
    "        similarity_shrinkage_threshold: float = 0.50,\n",
    "        recurrence_expansion_threshold: int = 3\n",
    "    ):\n",
    "        # Window constraints\n",
    "        self.min_time_seconds = min_time_seconds\n",
    "        self.max_time_seconds = max_time_seconds\n",
    "        self.min_flow_count = min_flow_count\n",
    "        self.max_flow_count = max_flow_count\n",
    "        \n",
    "        # Adaptation thresholds\n",
    "        self.similarity_expansion_threshold = similarity_expansion_threshold\n",
    "        self.similarity_shrinkage_threshold = similarity_shrinkage_threshold\n",
    "        self.recurrence_expansion_threshold = recurrence_expansion_threshold\n",
    "        \n",
    "        # Window state\n",
    "        self._buffer: deque[FlowRecord] = deque(maxlen=max_flow_count)\n",
    "        self._current_window_size_target = min_time_seconds\n",
    "        \n",
    "        # Statistics\n",
    "        self._recent_avg_similarities: deque[float] = deque(maxlen=10)\n",
    "        self._attack_type_counter: Dict[str, int] = {}\n",
    "        \n",
    "        # Metadata\n",
    "        self._total_flows_processed = 0\n",
    "        self._expansion_count = 0\n",
    "        self._shrinkage_count = 0\n",
    "    \n",
    "    def add_flow(self, flow: FlowRecord) -> None:\n",
    "        \"\"\"Add a new flow to the window with O(1) amortized complexity.\"\"\"\n",
    "        self._buffer.append(flow)\n",
    "        self._total_flows_processed += 1\n",
    "        self._update_statistics(flow)\n",
    "        self._adjust_window_size()\n",
    "        self._prune_expired_flows()\n",
    "    \n",
    "    def get_active_window(self) -> List[FlowRecord]:\n",
    "        \"\"\"Get all flows in the current active window.\"\"\"\n",
    "        if not self._buffer:\n",
    "            return []\n",
    "        \n",
    "        current_time = self._buffer[-1].timestamp\n",
    "        cutoff_time = current_time - self._current_window_size_target\n",
    "        \n",
    "        active_flows = [\n",
    "            flow for flow in self._buffer\n",
    "            if flow.timestamp >= cutoff_time\n",
    "        ]\n",
    "        \n",
    "        # Enforce minimum flow count\n",
    "        if len(active_flows) < self.min_flow_count and len(self._buffer) >= self.min_flow_count:\n",
    "            active_flows = list(self._buffer)[-self.min_flow_count:]\n",
    "        \n",
    "        return active_flows\n",
    "    \n",
    "    def get_window_summary(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get summary statistics for the current active window.\"\"\"\n",
    "        active_flows = self.get_active_window()\n",
    "        \n",
    "        if not active_flows:\n",
    "            return {\n",
    "                \"flow_count\": 0,\n",
    "                \"time_span_seconds\": 0.0,\n",
    "                \"avg_similarity\": 0.0,\n",
    "                \"attack_type_distribution\": {},\n",
    "                \"window_state\": \"empty\"\n",
    "            }\n",
    "        \n",
    "        time_span = active_flows[-1].timestamp - active_flows[0].timestamp\n",
    "        \n",
    "        all_similarities = []\n",
    "        attack_type_dist = {}\n",
    "        \n",
    "        for flow in active_flows:\n",
    "            for match in flow.retrieval_results:\n",
    "                similarity = match.get('similarity', match.get('distance', 0))\n",
    "                all_similarities.append(similarity)\n",
    "                \n",
    "                attack_type = match.get('attack_type', match.get('metadata', {}).get('attack_type', 'unknown'))\n",
    "                if attack_type != 'Normal':\n",
    "                    attack_type_dist[attack_type] = attack_type_dist.get(attack_type, 0) + 1\n",
    "        \n",
    "        avg_similarity = np.mean(all_similarities) if all_similarities else 0.0\n",
    "        window_state = self._get_window_state()\n",
    "        \n",
    "        return {\n",
    "            \"flow_count\": len(active_flows),\n",
    "            \"time_span_seconds\": time_span,\n",
    "            \"avg_similarity\": float(avg_similarity),\n",
    "            \"attack_type_distribution\": attack_type_dist,\n",
    "            \"window_state\": window_state,\n",
    "            \"current_target_seconds\": self._current_window_size_target,\n",
    "            \"total_processed\": self._total_flows_processed,\n",
    "            \"expansion_events\": self._expansion_count,\n",
    "            \"shrinkage_events\": self._shrinkage_count\n",
    "        }\n",
    "    \n",
    "    def reset_if_stable(self) -> bool:\n",
    "        \"\"\"Reset window if patterns have stabilized.\"\"\"\n",
    "        active_flows = self.get_active_window()\n",
    "        \n",
    "        if len(active_flows) < self.min_flow_count:\n",
    "            return False\n",
    "        \n",
    "        recent_similarities = []\n",
    "        for flow in active_flows[-10:]:\n",
    "            for match in flow.retrieval_results:\n",
    "                similarity = match.get('similarity', match.get('distance', 0))\n",
    "                recent_similarities.append(similarity)\n",
    "        \n",
    "        avg_recent_similarity = np.mean(recent_similarities) if recent_similarities else 0.0\n",
    "        \n",
    "        if avg_recent_similarity < 0.3:\n",
    "            self._buffer.clear()\n",
    "            self._recent_avg_similarities.clear()\n",
    "            self._attack_type_counter.clear()\n",
    "            self._current_window_size_target = self.min_time_seconds\n",
    "            return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def _update_statistics(self, flow: FlowRecord) -> None:\n",
    "        \"\"\"Update internal statistics for adaptive decision-making.\"\"\"\n",
    "        similarities = [\n",
    "            match.get('similarity', match.get('distance', 0))\n",
    "            for match in flow.retrieval_results\n",
    "        ]\n",
    "        avg_similarity = np.mean(similarities) if similarities else 0.0\n",
    "        self._recent_avg_similarities.append(avg_similarity)\n",
    "        \n",
    "        for match in flow.retrieval_results:\n",
    "            attack_type = match.get('attack_type', match.get('metadata', {}).get('attack_type', 'unknown'))\n",
    "            if attack_type != 'Normal':\n",
    "                self._attack_type_counter[attack_type] = self._attack_type_counter.get(attack_type, 0) + 1\n",
    "    \n",
    "    def _adjust_window_size(self) -> None:\n",
    "        \"\"\"Adjust window size based on recent patterns.\"\"\"\n",
    "        if len(self._recent_avg_similarities) < 5:\n",
    "            return\n",
    "        \n",
    "        recent_avg = np.mean(list(self._recent_avg_similarities))\n",
    "        should_expand = False\n",
    "        \n",
    "        if recent_avg > self.similarity_expansion_threshold:\n",
    "            should_expand = True\n",
    "        \n",
    "        max_recurrence = max(self._attack_type_counter.values()) if self._attack_type_counter else 0\n",
    "        if max_recurrence >= self.recurrence_expansion_threshold:\n",
    "            should_expand = True\n",
    "        \n",
    "        if should_expand:\n",
    "            new_target = min(\n",
    "                self._current_window_size_target * 1.5,\n",
    "                self.max_time_seconds\n",
    "            )\n",
    "            if new_target > self._current_window_size_target:\n",
    "                self._current_window_size_target = new_target\n",
    "                self._expansion_count += 1\n",
    "        \n",
    "        elif recent_avg < self.similarity_shrinkage_threshold:\n",
    "            new_target = max(\n",
    "                self._current_window_size_target * 0.8,\n",
    "                self.min_time_seconds\n",
    "            )\n",
    "            if new_target < self._current_window_size_target:\n",
    "                self._current_window_size_target = new_target\n",
    "                self._shrinkage_count += 1\n",
    "                self._attack_type_counter.clear()\n",
    "    \n",
    "    def _prune_expired_flows(self) -> None:\n",
    "        \"\"\"Remove flows older than max_time_seconds.\"\"\"\n",
    "        if not self._buffer:\n",
    "            return\n",
    "        \n",
    "        current_time = self._buffer[-1].timestamp\n",
    "        cutoff_time = current_time - self.max_time_seconds\n",
    "        \n",
    "        while self._buffer and self._buffer[0].timestamp < cutoff_time:\n",
    "            old_flow = self._buffer.popleft()\n",
    "            \n",
    "            for match in old_flow.retrieval_results:\n",
    "                attack_type = match.get('attack_type', match.get('metadata', {}).get('attack_type', 'unknown'))\n",
    "                if attack_type in self._attack_type_counter:\n",
    "                    self._attack_type_counter[attack_type] -= 1\n",
    "                    if self._attack_type_counter[attack_type] <= 0:\n",
    "                        del self._attack_type_counter[attack_type]\n",
    "    \n",
    "    def _get_window_state(self) -> str:\n",
    "        \"\"\"Determine current window state.\"\"\"\n",
    "        if len(self._recent_avg_similarities) < 3:\n",
    "            return \"initializing\"\n",
    "        \n",
    "        recent_avg = np.mean(list(self._recent_avg_similarities)[-3:])\n",
    "        \n",
    "        if recent_avg > self.similarity_expansion_threshold:\n",
    "            return \"expanding\"\n",
    "        elif recent_avg < self.similarity_shrinkage_threshold:\n",
    "            return \"contracting\"\n",
    "        else:\n",
    "            return \"stable\"\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self._buffer)\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        summary = self.get_window_summary()\n",
    "        return (\n",
    "            f\"AdaptiveTimeWindow(\"\n",
    "            f\"flows={summary['flow_count']}, \"\n",
    "            f\"span={summary['time_span_seconds']:.1f}s, \"\n",
    "            f\"state={summary['window_state']}\"\n",
    "            f\")\"\n",
    "        )\n",
    "\n",
    "print(\"âœ… AdaptiveTimeWindow class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b78f8a7",
   "metadata": {},
   "source": [
    "## âœ… Quick Validation Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0d9d848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Phase-3.1: Adaptive Time Window Implementation\n",
      "================================================================================\n",
      "âœ… AdaptiveTimeWindow initialized\n",
      "   Min window: 5.0s / 10 flows\n",
      "   Max window: 30.0s / 100 flows\n",
      "   Initial state: AdaptiveTimeWindow(flows=0, span=0.0s, state=empty)\n",
      "================================================================================\n",
      "âœ… Phase-3.1 class implementation complete!\n",
      "   Run validation notebook for comprehensive tests.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Create window instance\n",
    "window = AdaptiveTimeWindow(\n",
    "    min_time_seconds=5.0,\n",
    "    max_time_seconds=30.0,\n",
    "    min_flow_count=10,\n",
    "    max_flow_count=100\n",
    ")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"Phase-3.1: Adaptive Time Window Implementation\")\n",
    "print(\"=\"*80)\n",
    "print(f\"âœ… AdaptiveTimeWindow initialized\")\n",
    "print(f\"   Min window: {window.min_time_seconds}s / {window.min_flow_count} flows\")\n",
    "print(f\"   Max window: {window.max_time_seconds}s / {window.max_flow_count} flows\")\n",
    "print(f\"   Initial state: {window}\")\n",
    "print(\"=\"*80)\n",
    "print(\"âœ… Phase-3.1 class implementation complete!\")\n",
    "print(\"   Run validation notebook for comprehensive tests.\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4195b101",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸŽ‰ Phase-3.1 Complete!\n",
    "\n",
    "### âœ… Deliverables\n",
    "1. âœ… `FlowRecord` dataclass - Network flow representation\n",
    "2. âœ… `AdaptiveTimeWindow` class - Core temporal window manager\n",
    "3. âœ… Adaptive expansion/shrinkage logic\n",
    "4. âœ… O(1) amortized performance with deque\n",
    "5. âœ… Window state tracking (expanding/stable/contracting)\n",
    "\n",
    "### ðŸ“Š Key Features\n",
    "- **Dynamic sizing**: Expands (1.5Ã—) during attacks, shrinks (0.8Ã—) during benign periods\n",
    "- **Efficient pruning**: Time-based expiration with attack counter maintenance\n",
    "- **Statistics tracking**: Similarity trends and attack type recurrence\n",
    "- **Reset capability**: Clears window on stable benign patterns\n",
    "\n",
    "### ðŸš€ Next: Phase-3.2\n",
    "ChromaDB retrieval per flow (<50ms latency requirement)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
